# üõ∞Ô∏è Segmentaci√≥n sem√°ntica del dataset FLAIR con SegNet  
### Adaptaci√≥n del c√≥digo base de *‚ÄúBeyond RGB: Very High Resolution Urban Remote Sensing With Multimodal Deep Networks‚Äù*

**Autor:** Avdoni Sanchez Reinoso  
**Programa:** Maestr√≠a en Geom√°tica  
**A√±o:** 2025  

---

## üìò Descripci√≥n general

Este repositorio contiene una implementaci√≥n del modelo **SegNet** para **segmentaci√≥n sem√°ntica** aplicada al dataset **FLAIR #1**.  
La arquitectura y la organizaci√≥n del c√≥digo se basan en el trabajo de:

> Audebert, N., Le Saux, B., & Lef√®vre, S.  
> *Beyond RGB: Very High Resolution Urban Remote Sensing With Multimodal Deep Networks.*

Las principales caracter√≠sticas de este proyecto son:

- Uso de **im√°genes a√©reas multiespectrales** (RGB + NIR + nDSM) del dataset FLAIR.  
- Implementaci√≥n de **SegNet** como red encoder‚Äìdecoder totalmente convolucional.  
- Clasificaci√≥n de **13 clases** de uso/cobertura del suelo.  
- Entrenamiento **desde cero** (sin VGG-16 preentrenado).  
- Entrenamiento optimizado con **mixed precision (AMP)**, scheduler de LR y checkpoints peri√≥dicos.  
- Generaci√≥n de salidas de inferencia en formato RGB / Ground Truth / Predicci√≥n.

---

## üéØ Objetivo del proyecto

El objetivo de este trabajo es:

- **Replicar y adaptar** la estructura del c√≥digo de Audebert et al. para trabajar con el dataset **FLAIR #1**.  
- Entrenar un modelo SegNet capaz de segmentar 13 clases a partir de 5 canales de entrada (R, G, B, NIR, nDSM).  
- **Evaluar el rendimiento** del modelo (accuracy, F1-score por clase, Kappa, matriz de confusi√≥n).  
- Explorar **hiperpar√°metros adecuados** para este conjunto de datos bajo un entorno computacional limitado, con el fin de obtener resultados comparables con otros trabajos de segmentaci√≥n sem√°ntica en teledetecci√≥n.

---

## üóÇÔ∏è Dataset FLAIR

El dataset **FLAIR** es provisto por el Institut National de l‚ÄôInformation G√©ographique et Foresti√®re (IGN, Francia):  
üîó https://ignf.github.io/FLAIR/

Cada parche incluye:

- Imagen a√©rea de **512√ó512 px** a **0.2 m** de resoluci√≥n espacial.  
- 5 canales: **Red, Green, Blue, Near Infrared (NIR) y nDSM**.  
- M√°scara de segmentaci√≥n a 512√ó512 px con **19 clases**, de las cuales en este proyecto se usan **13** (baseline).

### Clases utilizadas (13)

1. Building  
2. Pervious surface  
3. Impervious surface  
4. Bare soil  
5. Water  
6. Coniferous  
7. Deciduous  
8. Brushwood  
9. Vineyard  
10. Herbaceous vegetation  
11. Agricultural land  
12. Plowed land  
13. Other  

---

### üîç Uso parcial del dataset FLAIR

El dataset completo FLAIR contiene m√°s de **60 000 parches** en train/val, adem√°s de dos conjuntos de test.  
Debido a las **limitaciones computacionales** del entorno local (en particular una GPU NVIDIA RTX 5060 Ti de 8 GB de VRAM), en este trabajo **no se utiliz√≥ la totalidad del dataset**.

En su lugar, se seleccion√≥ un **subconjunto representativo**, garantizando que cada imagen incluyera al menos una de las 13 clases objetivo. El tama√±o final empleado fue:

- **12 000 im√°genes** para entrenamiento (`train`)  
- **2 400 im√°genes** para validaci√≥n (`val`)  
- **2 400 im√°genes** para prueba (`test`)

Este muestreo mantiene la presencia de las clases principales y hace viable entrenar SegNet sin desbordar los recursos de hardware, preservando la utilidad del modelo para an√°lisis y comparaci√≥n de resultados.

---

## üíª Entorno de ejecuci√≥n

El c√≥digo fue ejecutado en un entorno local con las siguientes caracter√≠sticas principales:

- **Python 3.10**  
- Entorno virtual gestionado con **Anaconda**  
- **PyTorch (Nightly)** con soporte para **CUDA 12.8** (necesario para GPUs NVIDIA serie 5000).  
- Aceleraci√≥n por GPU: **NVIDIA RTX 5060 Ti (8 GB VRAM)**  

Librer√≠as principales:

- `torch`, `torchvision`  
- `numpy`  
- `matplotlib`  
- `scikit-learn`  
- `scikit-image`  
- `tifffile`  
- `tqdm`

Las versiones exactas pueden gestionarse mediante un archivo `requirements.txt`.

---

## üß† Arquitectura del modelo (SegNet)

El modelo implementado es una versi√≥n cl√°sica de **SegNet**, adaptada a:

- **5 canales de entrada** (`IN_CHANNELS = 5`) para trabajar con RGB + NIR + nDSM.  
- **13 clases de salida** (`N_CLASSES = 13`).

Caracter√≠sticas principales:

- Encoder‚Äìdecoder sim√©trico basado en bloques conv‚ÄìBatchNorm‚ÄìReLU.  
- Uso de `MaxPool2d` con `return_indices=True` y `MaxUnpool2d` para preservar informaci√≥n espacial.  
- √öltima capa con salida de logits para aplicar `CrossEntropyLoss`.  
- Entrenamiento **desde cero**, sin inicializaci√≥n con VGG-16 preentrenado.

---

## ‚öôÔ∏è Hiperpar√°metros principales

Algunos de los hiperpar√°metros m√°s relevantes utilizados en los experimentos:

| Par√°metro       | Valor                   | Descripci√≥n                                          |
|----------------|-------------------------|------------------------------------------------------|
| `WINDOW_SIZE`  | (256, 256)             | Tama√±o de los recortes aleatorios (random crops)    |
| `BATCH_SIZE`   | 10                   | Dependiente de la VRAM disponible                    |
| `IN_CHANNELS`  | 5                      | R, G, B, NIR, nDSM                                   |
| `N_CLASSES`    | 13                     | N√∫mero de clases de salida                           |
| `LR`           | 0.005                   | Learning rate base                                  |
| `optimizer`    | SGD                    | con `momentum=0.9`, `weight_decay=5e-4`             |
| `scheduler`    | MultiStepLR            | `milestones=[25, 35, 45]`, `gamma=0.1`              |
| `save_epoch`   | 5                      | Frecuencia de guardado de checkpoints               |
| `AMP`          | Activado               | `torch.amp.autocast` + `GradScaler`                 |

Se utiliza adem√°s `data augmentation` sencillo (rotaciones y flips) en el conjunto de entrenamiento, junto con recortes aleatorios controlados por `WINDOW_SIZE`.

---

## üìÇ Estructura del repositorio

Estructura del proyecto:

üìÅ ra√≠z del repositorio
‚îÇ
‚îú‚îÄ‚îÄ README.md                       # Este archivo
‚îú‚îÄ‚îÄ requirements.txt                # Dependencias del proyecto
‚îú‚îÄ‚îÄ SegNet_Data_FLAIR.ipynb              # Notebook principal
‚îÇ
‚îú‚îÄ‚îÄ Evaluacion_mod_FLAIR/           # Matrix y par√°metros de evaluaci√≥n
‚îú‚îÄ‚îÄ Mod_SegNet_FLAIR_epoch/         # Checkpoints del modelo por √©poca
‚îú‚îÄ‚îÄ Graf_perd/                      # Gr√°ficas de p√©rdida (loss vs epochs)
‚îú‚îÄ‚îÄ Predic_FLAIR_img/               # Ejemplos RGB / Ground Truth / Predicci√≥n
‚îú‚îÄ‚îÄ Inferencias_FLAIR_tiles/        # Predicciones por tile en test
‚îî‚îÄ‚îÄ modelo_SegNet_FLAIR/            # Modelo entrenado


## üöÄ Entrenamiento

El entrenamiento del modelo se realiza mediante la funci√≥n `train_model`, la cual implementa un ciclo completo de optimizaci√≥n incluyendo:

- Iteraci√≥n sobre el `DataLoader` de entrenamiento.
- Uso de **mixed precision (AMP)** para mejorar la eficiencia y reducir el consumo de VRAM.
- Actualizaci√≥n del *scheduler* al final de cada √©poca para ajustar la tasa de aprendizaje.
- Ejecuci√≥n de procesos adicionales cada `save_epoch` √©pocas:
  - Guardado de la curva de p√©rdida acumulada en la carpeta `Graf_perd/`.
  - Evaluaci√≥n del modelo utilizando el conjunto de validaci√≥n.
  - Generaci√≥n y almacenamiento de ejemplos RGB / Ground Truth / Predicci√≥n en `Predic_FLAIR_img/`.
  - Almacenamiento de un *checkpoint* con estado del modelo, optimizador y m√©tricas dentro de `Mod_SegNet_FLAIR_epoch/`.

### Ejemplo de ejecuci√≥n del entrenamiento

"train_model(net, train_loader, val_loader, optimizer, epochs=50, scheduler=scheduler)"

## Evaluaci√≥n del modelo

El modelo fue evaluado utilizando un conjunto de prueba independiente del entrenamiento y validaci√≥n.  
La evaluaci√≥n incluye:

- Exactitud global (Overall Accuracy)
- Matriz de confusi√≥n normalizada
- F1-score por clase
- Kappa de Cohen
- Visualizaciones comparativas entre *Ground Truth* y *Predicci√≥n*
- Inferencias colorizadas por tile

La funci√≥n de evaluaci√≥n genera autom√°ticamente figuras y m√©tricas, y permite almacenar los resultados para futuras comparaciones entre configuraciones o modelos.

---

## Inferencia y visualizaci√≥n de resultados

El notebook incluye herramientas para:

- Realizar inferencia sobre im√°genes del conjunto de prueba.
- Guardar resultados visuales en carpetas dedicadas.
- Generar composiciones RGB‚ÄìGT‚ÄìPredicci√≥n para inspecci√≥n manual.
- Exportar las predicciones en formato PNG colorizado.

Las predicciones se almacenan respetando el nombre original del parche, lo que facilita su trazabilidad y comparaci√≥n.

---

## Limitaciones del presente experimento

Aunque los resultados obtenidos permiten evaluar el rendimiento de SegNet sobre FLAIR, existen ciertas limitaciones:

- No se utiliz√≥ preentrenamiento en ImageNet (como en VGG-16), lo cual podr√≠a mejorar la generalizaci√≥n.
- Se trabaj√≥ con una fracci√≥n del dataset debido a restricciones de c√≥mputo.
- A pesar de incorporar data augmentation, podr√≠an explorarse t√©cnicas m√°s avanzadas.
- La arquitectura SegNet es relativamente antigua en comparaci√≥n con modelos modernos como DeepLabv3+, U-Net++, HRNet o SegFormer.

Estas limitaciones abren oportunidades para investigaciones futuras.

---

## Referencias

Audebert, N., Le Saux, B., & Lef√®vre, S. (2018).  
**Beyond RGB: Very High Resolution Urban Remote Sensing With Multimodal Deep Networks.**  
ISPRS Journal of Photogrammetry and Remote Sensing.

IGN (2023).  
**FLAIR: A Nationwide Dataset for Land Cover Semantic Segmentation.**  
https://ignf.github.io/FLAIR/

---

## Licencia

Este repositorio contiene √∫nicamente c√≥digo desarrollado por el autor.  
El dataset FLAIR **no se redistribuye** y debe obtenerse desde el sitio oficial del Institut National de l‚ÄôInformation G√©ographique et Foresti√®re (IGN).  
El uso del c√≥digo est√° permitido para fines acad√©micos y experimentales, salvo indicaci√≥n contraria.

---

